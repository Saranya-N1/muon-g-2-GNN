{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport torch\nimport torch\nimport torch.nn as nn\nimport time\nimport os\nimport logging\nimport ast\n\nfrom sklearn.neighbors import KDTree\n\nfrom torch.utils.data import DataLoader\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n# Load the saved model\n\n#from train_embed.py, load the model and Hit_Pair_Dataset\nmodel_path = \"model/trained_model.pt\"\nnet = MLP(input_dim=3, nb_hidden=256, nb_layer=3,mean=[0,0,0], std=[1,1,1], emb_dim=3)  # Instantiate the model with the same architecture as used during training\nnet.to(DEVICE)\nnet.load_state_dict(torch.load(model_path))\n\n# Set the model to evaluation mode\nnet.eval()\n\n# Now, you can use the loaded model for inference or other tasks\n# For example, to perform predictions on the test dataset:\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\nfrom hit_pair_dataset import Hit_Pair_Dataset\n# Example usage\ndata_filepath = \"/kaggle/input/dataset/time_dataset - time_dataset.csv (1).csv\"\nnb_samples = 16218\ndataset = Hit_Pair_Dataset(data_filepath, nb_samples)\n\n# Access elements from the dataset\nh_a, h_b, t, ti, mi = dataset[0]\n\n# Now all_preds contains the predictions made by the loaded model on the test dataset\n# You can use these predictions for further analysis or evaluation\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\ndef evaluate(net, experiment_dir, batch_size, eval_loader, plot_name):\n    nb_batch = len(eval_loader)\n    nb_eval = nb_batch * batch_size\n    net.eval()\n\n    all_preds = []\n    all_labels = []\n    with torch.autograd.no_grad():\n        epoch_score = 0\n        epoch_loss = 0\n        distances = []\n        embedded_points = []\n        time_values = []\n        muonID = []\n        labels = []\n\n        logging.info(\"\\nEvaluating {} {} samples.\".format(nb_eval, plot_name))\n        print_header()\n        for i, (hits_a, hits_b, target, time1, muon1) in enumerate(eval_loader):\n            hits_a = hits_a.to(DEVICE)\n            hits_b = hits_b.to(DEVICE)\n            target = target.to(DEVICE)\n            time = time1.to(DEVICE)\n            muon = muon1.to(DEVICE)\n#             t1 = time.time()\n\n            emb_h_a = net(hits_a)\n            emb_h_b = net(hits_b)\n\n            pred = nn.functional.pairwise_distance(emb_h_a, emb_h_b)\n            true_dist = target\n            loss = nn.functional.hinge_embedding_loss(pred, true_dist)\n\n            score = score_dist_accuracy(pred, target)\n            epoch_score += score * 100\n            epoch_loss += loss.item()\n\n            nb_proc = (i+1) * batch_size\n            if (i+1) % (nb_batch // 4) == 0:\n                print_eval_stats(nb_proc, epoch_loss / (i+1), epoch_score / (i+1))\n                \n#             pred = nn.functional.pairwise_distance(emb_h_a, emb_h_b)\n            pred_labels = (pred >= 0.0).float().cpu().numpy()\n            true_labels = target.cpu().numpy()\n\n            all_preds.extend(pred_labels)\n            all_labels.extend(true_labels)\n\n\n            # Calculate and store the pairwise distances\n            distances.extend(pred.tolist())\n            embedded_points.extend(emb_h_a.tolist())\n            labels.extend(target.tolist())\n            time_values.extend(time1.tolist())\n            muonID.extend(muon1.tolist())\n            \n        print_eval_stats(nb_eval, epoch_loss / nb_batch, epoch_score / nb_batch)\n        \n\n    return epoch_loss / nb_batch, epoch_score / nb_batch, distances, embedded_points, labels, time_values, muonID\n\neval_loss, eval_score, distances, embedded_points, labels, time_values, muonID = evaluate(net, experiment_dir, batch_size, train_loader, 'Eval')\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n# Convert the embedded points to a NumPy array\nembedded_points_e = np.array(embedded_points)\nimport pandas as pd\n\n# Create the \"embed_data\" folder if it doesn't exist\nfolder_path = '/kaggle/working/embed_data'\nif not os.path.exists(folder_path):\n    os.makedirs(folder_path)\n\n# Convert the lists to a pandas DataFrame\ndata = {\n    'Embedded Points': embedded_points,\n    'Time': time_values,\n    'muonID': muonID,\n    'Target': labels\n}\ndf = pd.DataFrame(data)\n\n\n# Define the output file path inside the \"embed_data\" folder\noutput_path = os.path.join(folder_path, 'embedded_points_table.csv')\n\n# Save the DataFrame as a CSV file\ndf.to_csv(output_path, index=False)\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n\n# Define the radius of the epsilon ball\nepsilon = 0.001\n\npoint_index = 34\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n#########################################\n#  Search for the nearest neighbours in the epsilon ball #\n#########################################\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.neighbors import KDTree\n\nfrom sklearn.neighbors import KDTree\nimport ast\n\ndata = pd.read_csv('/kaggle/working/embed_data/embedded_points_table.csv')\n\n# Convert the 'Embedded Points' column from string to numerical arrays\nembedded_points_e = np.array([ast.literal_eval(embedded_point) for embedded_point in data['Embedded Points']])\n\n# Convert the 'Time', 'muonID', and 'Target' columns to numpy arrays if needed\ntime = data[\"Time\"].values\nmuonID = data[\"muonID\"].values\nlabels = data['Target'].values\n\noptimal_radius = epsilon\n\n# Construct the KD-Tree\nkdtree = KDTree(embedded_points_e)\n\nquery_point = embedded_points_e[point_index]\n\n# Query the KD-Tree to find the indices of points within the epsilon ball\ndistances, indices = kdtree.query([query_point], k=len(embedded_points_e), return_distance=True)\n\n# Filter the indices based on the distance within the epsilon ball\nepsilon_indices = indices[0][distances[0] <= epsilon]\n\nnearest_neighbors = embedded_points_e[epsilon_indices]\n\nlen(epsilon_indices)\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n# Filter the time_data based on nearest neighbors\nnearest_neighbor_indices = epsilon_indices  # Use the nearest neighbor indices obtained from the KDTree query\nfiltered_data = data.iloc[nearest_neighbor_indices]\n\n# Access the filtered embedded points and time\nfiltered_embedded_points = filtered_data[\"Embedded Points\"].values\nfiltered_time = filtered_data[\"Time\"].values\nfiltered_muonID = filtered_data[\"muonID\"].values\n\n# Convert the embedded points to a NumPy array\nembedded_points_np = np.array([eval(embedded_point) for embedded_point in filtered_embedded_points])\n\nlen(epsilon_indices)\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n##############################################################\n# X-Y plot with query point    #\n#############################################################\n\ndf = pd.read_csv(/kaggle/input/data-sets/RecoOutPileup_TimeMod_uniform_1_recohitfile_training_data.csv)\n\n\n# Extract the x and y coordinates of the embedded points\nx_coords = df['x1']\ny_coords = df['y1']\n\n# Plot the x-y plane of embedded points\nplt.figure(figsize=(8, 8))\nplt.scatter(x_coords, y_coords, color='blue', label='Other Hit Points')\nplt.scatter(x_coords[point_index], y_coords[point_index], color='red', label='Query Point')\nplt.xlabel('X-coordinate')\nplt.ylabel('Y-coordinate')\nplt.legend()\nplt.title('Embedded Points in the X-Y Plane')\nplt.show()\n\n# Create the \"plots\" folder if it doesn't exist\noutput_folder = '/kaggle/working/plots'\nos.makedirs(output_folder, exist_ok=True)\n\n# Save the plot as an image in the \"plots\" folder\nplt.savefig(os.path.join(output_folder, 'x_y_plane_plot.png'))\nplt.close()\n\n##################################\n# Plot the whole embedded points #\n#################################\nplt.figure(figsize=(8, 8))\nplt.scatter(embedded_points_e[:, 0], embedded_points_e[:, 1], color='grey', label='Other Points')\nplt.scatter(nearest_neighbors[:, 0], nearest_neighbors[:, 1], color='blue', label='Nearest Neighbors')\nplt.scatter(query_point[0], query_point[1], color='red', label='Query Point')\nplt.xlabel('X-coordinate')\nplt.ylabel('Y-coordinate')\nplt.legend()\nplt.title('Embedded Points Scatter Plot')\nplt.show()\n\n# Save the plot as an image in the \"plots\" folder\nplt.savefig(os.path.join(output_folder, 'embedded_points_scatter_plot.png'))\nplt.close()\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n##########################################################\n# Create graph using the query point and its neighbours #\n#########################################################\n\n# Create the \"plots\" folder if it doesn't exist\noutput_folder = '/kaggle/working/plots'\nos.makedirs(output_folder, exist_ok=True)\n\nG = nx.Graph()\n\n# Add nodes for query point and its neighbor points\nG.add_node('Query Point', color='red')\nfor i, neighbor_point in enumerate(nearest_neighbors):\n    index = indices[0][i]  # Get the corresponding index for the neighbor point\n    G.add_node(f'Neighbor {index}', color='blue', index=index)\n\n# Add edges between query point and its neighbor points\nfor i in range(len(nearest_neighbors)):\n    index = indices[0][i]  # Get the corresponding index for the neighbor point\n    G.add_edge('Query Point', f'Neighbor {index}')\n\n# Plot the graph\npos = nx.spring_layout(G)  # Compute node positions for visualization\n\nplt.figure(figsize=(8, 6))\nnode_colors = [G.nodes[n]['color'] for n in G.nodes]\nnode_labels = {n: G.nodes[n]['index'] if 'index' in G.nodes[n] else '' for n in G.nodes}\nnx.draw_networkx_nodes(G, pos, node_color=node_colors, alpha=0.8)\nnx.draw_networkx_edges(G, pos, edge_color='black', width=1)\nnx.draw_networkx_labels(G, pos, labels=node_labels, font_color='black')\nplt.title('Graph with Query Point {} and Neighbor Points (direct edge)'.format(point_index))\nplt.axis('off')\n# Save the plot as an image in the \"plots\" folder\nplt.savefig(os.path.join(output_folder, 'graph_direct_edges.png'))\nplt.close()\nplt.show()\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n# Create a list to store the rows of the desired dataset\nresult_data = []\n\n# Get the query point and its embedded coordinates\nquery_point = embedded_points_np[point_index]\nz_query = query_point[2]\nt_qp = time[point_index]\n\n    # Loop through the nearest neighbors\nfor i in range(len(epsilon_indices)):\n   # Get the neighbor point and its embedded coordinates\n    neighbor_point = embedded_points_np[i]\n    z_neighbor = neighbor_point[2]\n    t_nn = time[i]\n\n    # Calculate z_diff and t_diff for each neighbor\n    z_diff_sqr = ((z_query*390.27-192.95) - (z_neighbor*390.27-192.95))**2\n    time_diff_sqr = (t_qp - t_nn)**2\n\n    # Append the row to the result_data list\n    result_data.append([point_index, i, muonID[point_index], muonID[i], z_query, z_neighbor, t_qp, t_nn, z_diff_sqr, time_diff_sqr])\n\n# Create a new DataFrame with the desired columns\nresult_df = pd.DataFrame(result_data, columns=[\"query_point\", \"nearest_neighbors\", \"muonID_query\", \"muonID_neighbor\", \"z_query\", \"z_neighbor\", \"t_qp\", \"t_nn\", \"z_diff_sqr\", \"time_diff_sqr\"])\n\n\n# Save the DataFrame to a new CSV file\nresult_df.to_csv(\"/kaggle/working/embed_data/refine_dataset.csv\", index=False)\nresult_df\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n","metadata":{"_uuid":"fa50d9de-0041-4b7c-898b-52c7e3e6f505","_cell_guid":"23567842-56d3-481a-b687-8ed238cbdfed","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}